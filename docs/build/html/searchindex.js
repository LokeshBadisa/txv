Search.setIndex({"docnames": ["api_reference", "exp", "exp/AR", "exp/BA", "exp/BI", "exp/GA", "exp/GS", "exp/IG", "exp/LRP", "exp/RA", "exp/TAM", "index", "tutorials", "tutorials/explanation_methods_visualization", "tutorials/model_internals_visualization", "txv", "utils", "utils/postprocess", "utils/print_top_classes", "utils/read_image", "utils/read_image2", "utils/show_exp_on_image", "vit"], "filenames": ["api_reference.rst", "exp.rst", "exp/AR.rst", "exp/BA.rst", "exp/BI.rst", "exp/GA.rst", "exp/GS.rst", "exp/IG.rst", "exp/LRP.rst", "exp/RA.rst", "exp/TAM.rst", "index.rst", "tutorials.rst", "tutorials/explanation_methods_visualization.nblink", "tutorials/model_internals_visualization.nblink", "txv.rst", "utils.rst", "utils/postprocess.rst", "utils/print_top_classes.rst", "utils/read_image.rst", "utils/read_image2.rst", "utils/show_exp_on_image.rst", "vit.rst"], "titles": ["txv reference", "exp", "AttentionRollout", "BeyondAttention", "BeyondIntuition", "GenericAttention", "GradSAM", "IntegratedGradients", "LRP", "RawAttention", "TAM", "txv documentation", "Tutorials", "Let\u2019s install the txv package.", "Let\u2019s install the txv package", "txv.vit", "utils", "postprocess", "print_top_classes", "read_image", "read_image2", "show_exp_on_image", "vit"], "terms": {"version": [0, 3, 8, 11], "0": [0, 2, 3, 4, 8, 9, 10, 11, 13, 19, 20], "1": [0, 2, 3, 5, 9, 11, 13, 14, 21], "exp": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13], "lrp": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 15, 22], "integratedgradi": [0, 1, 13], "rawattent": [0, 1, 13], "attentionrollout": [0, 1, 13], "gradsam": [0, 1], "beyondattent": [0, 1, 13], "genericattent": [0, 1, 13], "tam": [0, 1], "beyondintuit": [0, 1, 13], "util": [0, 13, 14, 17, 18, 19, 20, 21], "read_imag": [0, 13, 14, 16], "read_image2": [0, 16], "print_top_class": [0, 13, 16], "postprocess": [0, 13, 16], "show_exp_on_imag": [0, 13, 16], "vit": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "avail": 0, "model": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18], "class": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 18], "txv": [2, 3, 4, 5, 6, 7, 8, 9, 10, 17, 18, 19, 20, 21, 22], "modul": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "link": [2, 3, 4, 5, 6, 7, 8, 10, 11], "paper": [2, 3, 4, 5, 6, 7, 8, 10], "quantifi": 2, "attent": [2, 3, 4, 5, 6, 9, 10, 12], "flow": [2, 10], "transform": [2, 3, 4, 5, 6, 10, 11, 12], "thi": [2, 9, 10, 12, 19, 20, 21], "i": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 18, 19, 20, 21], "agnost": [2, 9], "explan": [2, 8, 9, 12, 21], "method": [2, 4, 9, 10, 11, 12], "therefor": [2, 9], "an": [2, 3, 8, 9, 11, 21], "index": [2, 3, 4, 5, 6, 7, 8, 9, 10], "cannot": [2, 9], "pass": [2, 3, 8, 9, 14], "argument": [2, 9], "__init__": [2, 3, 4, 5, 6, 7, 8, 9, 10], "none": [2, 3, 4, 5, 6, 7, 8, 10, 21], "paramet": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 17, 18, 19, 20, 21, 22], "torch": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 17, 18], "nn": [2, 3, 4, 5, 6, 7, 8, 9, 10], "A": [2, 3, 4, 5, 6, 7, 8, 9, 10], "from": [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 22], "us": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 21], "fals": [2, 4, 5, 6, 7, 9, 10, 15, 22], "have": [2, 4, 5, 6, 7, 9, 10, 13], "higher": [2, 4, 5, 6, 7, 9, 10], "memori": [2, 4, 5, 6, 7, 9, 10], "footprint": [2, 4, 5, 6, 7, 9, 10], "explain": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13], "input": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 17], "tensor": [2, 3, 4, 5, 6, 7, 8, 9, 10, 17, 18, 19, 20], "layer": [2, 4, 5, 8, 9, 10, 13, 22], "int": [2, 3, 4, 5, 6, 7, 8, 9, 10, 18, 21], "abm": [2, 3, 4, 5, 6, 8, 10], "bool": [2, 3, 4, 5, 6, 8, 10, 15, 22], "true": [2, 3, 4, 5, 6, 8, 10, 14, 15, 21, 22], "option": [2, 3, 4, 5, 6, 7, 8, 9, 10, 18, 19, 20], "number": [2, 4, 5, 7, 9, 10, 18], "start": [2, 4, 5, 11], "comput": [2, 4, 5, 10], "rollout": 2, "default": [2, 3, 4, 5, 6, 7, 8, 9, 10, 18, 19, 20, 21], "leq": [2, 9], "depth": [2, 9], "architectur": [2, 3, 4, 5, 6, 8], "base": [2, 3, 4, 5, 6, 8, 10, 21, 22], "modif": [2, 3, 4, 5, 6, 8], "interpret": [3, 5], "beyond": [3, 4, 12], "visual": [3, 9, 11, 12, 13], "The": [3, 8, 11, 17, 18, 19, 20, 21], "must": [3, 8], "you": [3, 8, 11], "can": [3, 8, 11], "function": [3, 8, 11, 19, 20, 21], "alpha": [3, 8], "float": [3, 8, 21], "kwarg": [3, 5, 15, 18], "predict": [3, 4, 5, 6, 7, 8, 10, 18], "valu": [3, 8, 12, 13], "intuit": [4, 12], "rethink": 4, "token": [4, 9], "attribut": [4, 7, 17], "insid": [4, 10], "liter": 4, "head": 4, "step": [4, 7, 10], "20": [4, 7, 10], "baselin": [4, 7, 10], "type": [4, 9, 21], "map": [4, 6, 9, 17, 21], "wise": [4, 8, 22], "weight": [4, 5, 10], "riemann": [4, 7, 10], "approxim": [4, 7, 10], "integr": [4, 7, 10], "zero": [4, 7, 10], "gener": 5, "bi": [5, 13], "modal": 5, "encod": 5, "decod": 5, "grad": 6, "sam": 6, "via": 6, "gradient": 6, "self": 6, "axiomat": 7, "deep": 7, "network": 7, "relev": [8, 22], "propag": [8, 22], "On": 8, "pixel": 8, "non": 8, "linear": 8, "classifi": 8, "decis": 8, "5": [8, 13, 14, 19, 20], "basic": 9, "return": [9, 21, 22], "specifi": 9, "dimens": 9, "ar": [9, 10, 11, 13], "batch_siz": [9, 14], "num_head": [9, 14], "num_token": 9, "perform": 9, "necessari": 9, "post": 9, "process": [9, 14], "oper": 9, "take": [9, 13], "proper": 9, "care": 9, "choos": 9, "between": 9, "cl": [9, 13], "other": 9, "inform": 10, "vision": [10, 11, 12], "markov": 10, "chain": 10, "onli": [10, 11], "support": 10, "small": 10, "larg": 10, "l_end": 10, "end": 10, "By": 10, "last_lay": 10, "instal": 11, "sourc": 11, "repositori": 11, "issu": 11, "tracker": 11, "packag": 11, "It": 11, "provid": 11, "cam": [11, 13, 14, 21], "like": [11, 12], "built": 11, "top": [11, 13, 18], "transformerinterp": 11, "note": 11, "work": 11, "defin": 11, "api": 11, "refer": 11, "guid": 11, "contain": 11, "detail": 11, "descript": 11, "object": 11, "includ": 11, "describ": 11, "how": 11, "which": 11, "To": 11, "tutori": 11, "understand": 11, "should": [11, 21], "unison": 11, "design": 11, "help": [11, 12], "get": [11, 14], "model_internals_visu": 12, "ipynb": 12, "extract": 12, "queri": 12, "kei": 12, "matric": 12, "them": 12, "explanation_methods_visu": 12, "etc": 12, "pip": [13, 14], "sy": 13, "path": [13, 19, 20], "append": 13, "matplotlib": [13, 14], "pyplot": [13, 14], "plt": [13, 14], "3": [13, 14], "devic": [13, 14], "cuda": [13, 14], "vit_base_patch16_224": [13, 14, 15, 22], "model2": 13, "4": [13, 14], "read": 13, "imag": [13, 17, 19, 20, 21], "zebra": [13, 14], "eleph": [13, 14], "png": [13, 14], "output": [13, 14, 18], "6": [13, 14], "print": [13, 18], "340": 13, "12": 13, "749": 13, "prob": 13, "94": 13, "386": 13, "african": 13, "loxodonta": 13, "africana": 13, "9": [13, 14], "485": 13, "101": 13, "tusker": 13, "7": [13, 14], "923": 13, "8": [13, 14], "385": 13, "indian": 13, "elepha": 13, "maximu": 13, "684": 13, "352": 13, "impala": 13, "aepycero": 13, "melampu": 13, "946": 13, "351": 13, "hartebeest": 13, "460": 13, "343": 13, "warthog": 13, "416": 13, "ostrich": 13, "struthio": 13, "camelu": 13, "292": 13, "353": 13, "gazel": 13, "248": 13, "293": 13, "cheetah": 13, "chetah": 13, "acinonyx": 13, "jubatu": 13, "881": 13, "mask_lrp": 13, "inp": [13, 14], "imshow": [13, 14], "axi": [13, 14], "off": [13, 14], "show": 13, "ig": 13, "mask_ig": 13, "ra": 13, "mask_ra": 13, "mean": [13, 19, 20], "over": 13, "all": 13, "dim": [13, 14], "uncom": 13, "below": 13, "line": 13, "distil": 13, "thei": 13, "dist": 13, "also": 13, "10": [13, 14, 18], "mask_ar": 13, "11": 13, "mask_gradsam": 13, "ba": 13, "mask_ba": 13, "13": 13, "ga": 13, "mask_ga": 13, "14": 13, "mask_tam": 13, "15": 13, "mask_bi": 13, "16": 13, "2": [14, 21], "attn": 14, "issaveq": 14, "issavek": 14, "issavev": 14, "forward": 14, "get_q": 14, "shape": 14, "num_patch": 14, "do": 14, "requir": 14, "final": [14, 21], "get_k": 14, "lt": 14, "axesimag": 14, "0x7f119e3cbeb0": 14, "gt": 14, "get_v": 14, "0x7f119e2efc70": 14, "get_attn": 14, "0x7f119e2efac0": 14, "deit_base_distilled_patch16_224": [15, 22], "pretrain": [15, 22], "deit_base_patch16_224": [15, 22], "deit_small_distilled_patch16_224": [15, 22], "deit_small_patch16_224": [15, 22], "deit_tiny_distilled_patch16_224": [15, 22], "vit_dino_base_patch16_224": [15, 22], "vit_dino_base_patch8_224": [15, 22], "vit_dino_small_patch16_224": [15, 22], "vit_dino_small_patch8_224": [15, 22], "vit_large_patch16_224": [15, 22], "vit_mae_base_patch16_224": [15, 22], "vit_mae_large_patch16_224": [15, 22], "vit_small_patch16_224": [15, 22], "doe": 17, "bilinear": 17, "interpol": 17, "match": 17, "size": 17, "ntop": 18, "image_path": [19, 20], "str": [19, 20], "list": [19, 20], "stddev": [19, 20], "tupl": [19, 20], "combin": [19, 20], "resiz": [19, 20], "256": 19, "center": 19, "crop": 19, "224": [19, 20], "normal": [19, 20], "file": [19, 20], "standard": [19, 20], "deviat": [19, 20], "ndarrai": 21, "mask": 21, "colormap": 21, "image_weight": 21, "overlai": 21, "heatmap": 21, "img": 21, "rgb": 21, "bgr": 21, "format": 21, "use_rgb": 21, "whether": 21, "set": 21, "opencv": 21, "result": 21, "deit": 22, "mae": 22, "dino": 22, "initi": 22, "abov": 22, "If": 22, "pre": 22, "train": 22, "imagenet": 22, "enabl": 22, "import": 22, "eval": 22}, "objects": {"": [[22, 0, 1, "", "model"]], "txv.exp": [[2, 1, 1, "", "AttentionRollout"], [3, 1, 1, "", "BeyondAttention"], [4, 1, 1, "", "BeyondIntuition"], [5, 1, 1, "", "GenericAttention"], [6, 1, 1, "", "GradSAM"], [7, 1, 1, "", "IntegratedGradients"], [8, 1, 1, "", "LRP"], [9, 1, 1, "", "RawAttention"], [10, 1, 1, "", "TAM"]], "txv.exp.AttentionRollout": [[2, 2, 1, "", "__init__"], [2, 2, 1, "", "explain"]], "txv.exp.BeyondAttention": [[3, 2, 1, "", "__init__"], [3, 2, 1, "", "explain"]], "txv.exp.BeyondIntuition": [[4, 2, 1, "", "__init__"], [4, 2, 1, "", "explain"]], "txv.exp.GenericAttention": [[5, 2, 1, "", "__init__"], [5, 2, 1, "", "explain"]], "txv.exp.GradSAM": [[6, 2, 1, "", "__init__"], [6, 2, 1, "", "explain"]], "txv.exp.IntegratedGradients": [[7, 2, 1, "", "__init__"], [7, 2, 1, "", "explain"]], "txv.exp.LRP": [[8, 2, 1, "", "__init__"], [8, 2, 1, "", "explain"]], "txv.exp.RawAttention": [[9, 2, 1, "", "__init__"], [9, 2, 1, "", "explain"]], "txv.exp.TAM": [[10, 2, 1, "", "__init__"], [10, 2, 1, "", "explain"]], "txv.utils": [[17, 0, 1, "", "postprocess"], [18, 0, 1, "", "print_top_classes"], [19, 0, 1, "", "read_image"], [20, 0, 1, "", "read_image2"], [21, 0, 1, "", "show_exp_on_image"]], "txv": [[15, 3, 0, "-", "vit"]], "txv.vit": [[15, 0, 1, "", "deit_base_distilled_patch16_224"], [15, 0, 1, "", "deit_base_patch16_224"], [15, 0, 1, "", "deit_small_distilled_patch16_224"], [15, 0, 1, "", "deit_small_patch16_224"], [15, 0, 1, "", "deit_tiny_distilled_patch16_224"], [15, 0, 1, "", "vit_base_patch16_224"], [15, 0, 1, "", "vit_dino_base_patch16_224"], [15, 0, 1, "", "vit_dino_base_patch8_224"], [15, 0, 1, "", "vit_dino_small_patch16_224"], [15, 0, 1, "", "vit_dino_small_patch8_224"], [15, 0, 1, "", "vit_large_patch16_224"], [15, 0, 1, "", "vit_mae_base_patch16_224"], [15, 0, 1, "", "vit_mae_large_patch16_224"], [15, 0, 1, "", "vit_small_patch16_224"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method", "3": "py:module"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "module", "Python module"]}, "titleterms": {"txv": [0, 11, 13, 14, 15], "refer": 0, "exp": 1, "attentionrollout": 2, "beyondattent": 3, "beyondintuit": 4, "genericattent": 5, "gradsam": [6, 13], "integratedgradi": 7, "lrp": [8, 13], "rawattent": 9, "tam": [10, 13], "document": 11, "tutori": [12, 13, 14], "let": [13, 14], "": [13, 14], "instal": [13, 14], "packag": [13, 14], "import": [13, 14], "necessari": [13, 14], "librari": [13, 14], "model": [13, 14, 22], "initi": 13, "we": [13, 14], "us": [13, 14], "vit": [13, 14, 15, 22], "base": [13, 14], "patch16": [13, 14], "224": [13, 14], "thi": [13, 14], "you": [13, 14], "can": [13, 14], "try": [13, 14], "other": [13, 14], "avail": [13, 14, 22], "section": [13, 14], "well": [13, 14], "note": [13, 14], "work": [13, 14], "onli": [13, 14], "2": 13, "one": 13, "true": 13, "fals": 13, "explan": 13, "method": 13, "like": 13, "beyond": 13, "attent": [13, 14], "requir": 13, "relev": 13, "propog": 13, "which": 13, "i": 13, "enabl": 13, "through": 13, "model1": 13, "further": 13, "except": 13, "integr": 13, "gradient": [13, 14], "raw": 13, "rollout": 13, "gener": 13, "transit": 13, "map": [13, 14], "intuit": 13, "token": [13, 14], "wise": 13, "head": [13, 14], "turn": 14, "save": 14, "intern": 14, "visual": 14, "them": 14, "next": 14, "step": 14, "ar": 14, "default": 14, "here": 14, "7th": 14, "block": 14, "0": 14, "index": 14, "q": 14, "k": 14, "v": 14, "matric": 14, "extract": 14, "queri": 14, "matrix": 14, "take": 14, "mean": 14, "across": 14, "head_dim": 14, "remov": 14, "cl": 14, "postprocess": [14, 17], "doe": 14, "normal": 14, "bilinear": 14, "interpol": 14, "show_exp_on_imag": [14, 21], "merg": 14, "imag": 14, "show": 14, "result": 14, "similarli": 14, "kei": 14, "valu": 14, "now": 14, "util": 16, "print_top_class": 18, "read_imag": 19, "read_image2": 20, "exampl": 22}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"txv reference": [[0, "txv-reference"]], "exp": [[1, "exp"]], "AttentionRollout": [[2, "attentionrollout"]], "BeyondAttention": [[3, "beyondattention"]], "BeyondIntuition": [[4, "beyondintuition"]], "GenericAttention": [[5, "genericattention"]], "GradSAM": [[6, "gradsam"], [13, "GradSAM"]], "IntegratedGradients": [[7, "integratedgradients"]], "LRP": [[8, "lrp"], [13, "LRP"]], "RawAttention": [[9, "rawattention"]], "TAM": [[10, "tam"]], "txv documentation": [[11, "txv-documentation"]], "Tutorials": [[12, "tutorials"]], "Let\u2019s install the txv package.": [[13, "Let's-install-the-txv-package."]], "Import necessary libraries.": [[13, "Import-necessary-libraries."], [14, "Import-necessary-libraries."]], "Model Initialization": [[13, "Model-Initialization"]], "We will use vit-base-patch16-224 model in this tutorial. You can try this with other models in Available Models section as well. Note that this package works with models in Available Models section only. We initialize 2 models, one with lrp=True and other with lrp=False. LRP based explanation methods like LRP and Beyond Attention require relevance propogation which is enabled through lrp=True.": [[13, "We-will-use-vit-base-patch16-224-model-in-this-tutorial.-You-can-try-this-with-other-models-in-Available-Models-section-as-well.-Note-that-this-package-works-with-models-in-Available-Models-section-only.-We-initialize-2-models,-one-with-lrp=True-and-other-with-lrp=False.-LRP-based-explanation-methods-like-LRP-and-Beyond-Attention-require-relevance-propogation-which-is-enabled-through-lrp=True."]], "Note that we use model1 for LRP which is initialized with lrp=True which is not used in further explanation methods(except Beyond Attention).": [[13, "Note-that-we-use-model1-for-LRP-which-is-initialized-with-lrp=True-which-is-not-used-in-further-explanation-methods(except-Beyond-Attention)."]], "Integrated Gradients": [[13, "Integrated-Gradients"]], "Raw Attention": [[13, "Raw-Attention"]], "Attention Rollout": [[13, "Attention-Rollout"]], "Beyond Attention": [[13, "Beyond-Attention"]], "Generic Attention": [[13, "Generic-Attention"]], "Transition Attention Map(TAM)": [[13, "Transition-Attention-Map(TAM)"]], "Beyond Intuition - token-wise": [[13, "Beyond-Intuition---token-wise"]], "Beyond Intuition - head-wise": [[13, "Beyond-Intuition---head-wise"]], "Let\u2019s install the txv package": [[14, "Let's-install-the-txv-package"]], "We will use vit-base-patch16-224 model in this tutorial. You can try this with other models in Available Models section as well. Note that this package works with models in Available Models section only.": [[14, "We-will-use-vit-base-patch16-224-model-in-this-tutorial.-You-can-try-this-with-other-models-in-Available-Models-section-as-well.-Note-that-this-package-works-with-models-in-Available-Models-section-only."]], "Turn on saving of the model internals to visualize them in the next steps. Attention map and it\u2019s gradients are saved by default. Here we are saving 7th block\u2019s (0-indexing) Q, K and V matrices. You can save other block\u2019s matrices as well.": [[14, "Turn-on-saving-of-the-model-internals-to-visualize-them-in-the-next-steps.-Attention-map-and-it's-gradients-are-saved-by-default.-Here-we-are-saving-7th-block's-(0-indexing)-Q,-K-and-V-matrices.-You-can-save-other-block's-matrices-as-well."]], "Extract the query matrix and take mean across heads and head_dim. Visualize with removing the CLS token. postprocess does normalization and bilinear interpolation of the query. show_exp_on_image merges image and query to show the resultant visualization.": [[14, "Extract-the-query-matrix-and-take-mean-across-heads-and-head_dim.-Visualize-with-removing-the-CLS-token.-postprocess-does-normalization-and-bilinear-interpolation-of-the-query.-show_exp_on_image-merges-image-and-query-to-show-the-resultant-visualization."]], "Similarly, let\u2019s visualize key and value": [[14, "Similarly,-let's-visualize-key-and-value"]], "Now, let\u2019s visualize attention.": [[14, "Now,-let's-visualize-attention."]], "txv.vit": [[15, "module-txv.vit"]], "utils": [[16, "utils"]], "postprocess": [[17, "postprocess"]], "print_top_classes": [[18, "print-top-classes"]], "read_image": [[19, "read-image"]], "read_image2": [[20, "read-image2"]], "show_exp_on_image": [[21, "show-exp-on-image"]], "vit": [[22, "vit"]], "Available models": [[22, "available-models"]], "Example:": [[22, "example"]]}, "indexentries": {"attentionrollout (class in txv.exp)": [[2, "txv.exp.AttentionRollout"]], "__init__() (txv.exp.attentionrollout method)": [[2, "txv.exp.AttentionRollout.__init__"]], "explain() (txv.exp.attentionrollout method)": [[2, "txv.exp.AttentionRollout.explain"]], "beyondattention (class in txv.exp)": [[3, "txv.exp.BeyondAttention"]], "__init__() (txv.exp.beyondattention method)": [[3, "txv.exp.BeyondAttention.__init__"]], "explain() (txv.exp.beyondattention method)": [[3, "txv.exp.BeyondAttention.explain"]], "beyondintuition (class in txv.exp)": [[4, "txv.exp.BeyondIntuition"]], "__init__() (txv.exp.beyondintuition method)": [[4, "txv.exp.BeyondIntuition.__init__"]], "explain() (txv.exp.beyondintuition method)": [[4, "txv.exp.BeyondIntuition.explain"]], "genericattention (class in txv.exp)": [[5, "txv.exp.GenericAttention"]], "__init__() (txv.exp.genericattention method)": [[5, "txv.exp.GenericAttention.__init__"]], "explain() (txv.exp.genericattention method)": [[5, "txv.exp.GenericAttention.explain"]], "gradsam (class in txv.exp)": [[6, "txv.exp.GradSAM"]], "__init__() (txv.exp.gradsam method)": [[6, "txv.exp.GradSAM.__init__"]], "explain() (txv.exp.gradsam method)": [[6, "txv.exp.GradSAM.explain"]], "integratedgradients (class in txv.exp)": [[7, "txv.exp.IntegratedGradients"]], "__init__() (txv.exp.integratedgradients method)": [[7, "txv.exp.IntegratedGradients.__init__"]], "explain() (txv.exp.integratedgradients method)": [[7, "txv.exp.IntegratedGradients.explain"]], "lrp (class in txv.exp)": [[8, "txv.exp.LRP"]], "__init__() (txv.exp.lrp method)": [[8, "txv.exp.LRP.__init__"]], "explain() (txv.exp.lrp method)": [[8, "txv.exp.LRP.explain"]], "rawattention (class in txv.exp)": [[9, "txv.exp.RawAttention"]], "__init__() (txv.exp.rawattention method)": [[9, "txv.exp.RawAttention.__init__"]], "explain() (txv.exp.rawattention method)": [[9, "txv.exp.RawAttention.explain"]], "tam (class in txv.exp)": [[10, "txv.exp.TAM"]], "__init__() (txv.exp.tam method)": [[10, "txv.exp.TAM.__init__"]], "explain() (txv.exp.tam method)": [[10, "txv.exp.TAM.explain"]], "deit_base_distilled_patch16_224() (in module txv.vit)": [[15, "txv.vit.deit_base_distilled_patch16_224"]], "deit_base_patch16_224() (in module txv.vit)": [[15, "txv.vit.deit_base_patch16_224"]], "deit_small_distilled_patch16_224() (in module txv.vit)": [[15, "txv.vit.deit_small_distilled_patch16_224"]], "deit_small_patch16_224() (in module txv.vit)": [[15, "txv.vit.deit_small_patch16_224"]], "deit_tiny_distilled_patch16_224() (in module txv.vit)": [[15, "txv.vit.deit_tiny_distilled_patch16_224"]], "module": [[15, "module-txv.vit"]], "txv.vit": [[15, "module-txv.vit"]], "vit_base_patch16_224() (in module txv.vit)": [[15, "txv.vit.vit_base_patch16_224"]], "vit_dino_base_patch16_224() (in module txv.vit)": [[15, "txv.vit.vit_dino_base_patch16_224"]], "vit_dino_base_patch8_224() (in module txv.vit)": [[15, "txv.vit.vit_dino_base_patch8_224"]], "vit_dino_small_patch16_224() (in module txv.vit)": [[15, "txv.vit.vit_dino_small_patch16_224"]], "vit_dino_small_patch8_224() (in module txv.vit)": [[15, "txv.vit.vit_dino_small_patch8_224"]], "vit_large_patch16_224() (in module txv.vit)": [[15, "txv.vit.vit_large_patch16_224"]], "vit_mae_base_patch16_224() (in module txv.vit)": [[15, "txv.vit.vit_mae_base_patch16_224"]], "vit_mae_large_patch16_224() (in module txv.vit)": [[15, "txv.vit.vit_mae_large_patch16_224"]], "vit_small_patch16_224() (in module txv.vit)": [[15, "txv.vit.vit_small_patch16_224"]], "postprocess() (in module txv.utils)": [[17, "txv.utils.postprocess"]], "print_top_classes() (in module txv.utils)": [[18, "txv.utils.print_top_classes"]], "read_image() (in module txv.utils)": [[19, "txv.utils.read_image"]], "read_image2() (in module txv.utils)": [[20, "txv.utils.read_image2"]], "show_exp_on_image() (in module txv.utils)": [[21, "txv.utils.show_exp_on_image"]], "built-in function": [[22, "model"]], "model()": [[22, "model"]]}})